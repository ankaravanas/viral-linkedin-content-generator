#!/usr/bin/env python3
"""
LinkedIn Viral Content Generator MCP Server

A minimal FastMCP server that integrates with Apify actors to scrape social media content
and generate viral LinkedIn posts using hook templates and content patterns.
"""

import os
import json
import requests
import time
from typing import Dict, List, Optional, Any
from pathlib import Path

from fastmcp import FastMCP
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

# Initialize FastMCP server
mcp = FastMCP("LinkedIn Viral Content Generator")

# Configuration
APIFY_TOKEN = os.getenv("APIFY_TOKEN")
APIFY_BASE_URL = "https://api.apify.com/v2"

# Knowledge base paths
KNOWLEDGE_BASE_DIR = Path(__file__).parent / "knowledge_base"
HOOKS_FILE = KNOWLEDGE_BASE_DIR / "hooks.md"
CONTENT_TEMPLATES_FILE = KNOWLEDGE_BASE_DIR / "content_templates.md"

# Global storage for workflow state
workflow_state = {
    "current_niche": None,
    "selected_platform": None,
    "discovered_content": [],
    "selected_content": None,
    "analyzed_data": {},
    "selected_hooks": [],
    "content_ideas": [],
    "generated_posts": []
}


def make_apify_request(actor_id: str, input_data: Dict[str, Any]) -> Dict[str, Any]:
    """Make a request to an Apify actor and wait for completion."""
    if not APIFY_TOKEN:
        raise ValueError("APIFY_TOKEN environment variable is required")
    
    # Start the actor run
    run_url = f"{APIFY_BASE_URL}/acts/{actor_id}/runs"
    headers = {"Authorization": f"Bearer {APIFY_TOKEN}"}
    
    response = requests.post(run_url, json=input_data, headers=headers)
    response.raise_for_status()
    
    run_data = response.json()
    run_id = run_data["data"]["id"]
    
    # Poll for completion
    status_url = f"{APIFY_BASE_URL}/acts/{actor_id}/runs/{run_id}"
    max_wait = 300  # 5 minutes max
    wait_time = 0
    
    while wait_time < max_wait:
        status_response = requests.get(status_url, headers=headers)
        status_response.raise_for_status()
        status_data = status_response.json()
        
        if status_data["data"]["status"] == "SUCCEEDED":
            # Get the dataset items
            dataset_id = status_data["data"]["defaultDatasetId"]
            dataset_url = f"{APIFY_BASE_URL}/datasets/{dataset_id}/items"
            
            dataset_response = requests.get(dataset_url, headers=headers)
            dataset_response.raise_for_status()
            
            return {"status": "success", "data": dataset_response.json()}
        
        elif status_data["data"]["status"] in ["FAILED", "ABORTED", "TIMED-OUT"]:
            return {"status": "failed", "error": f"Actor run failed with status: {status_data['data']['status']}"}
        
        time.sleep(10)
        wait_time += 10
    
    return {"status": "failed", "error": "Actor run timed out"}


def load_knowledge_base() -> Dict[str, str]:
    """Load hook templates and content templates from knowledge base."""
    knowledge = {"hooks": "", "content_templates": ""}
    
    if HOOKS_FILE.exists():
        with open(HOOKS_FILE, "r", encoding="utf-8") as f:
            knowledge["hooks"] = f.read()
    
    if CONTENT_TEMPLATES_FILE.exists():
        with open(CONTENT_TEMPLATES_FILE, "r", encoding="utf-8") as f:
            knowledge["content_templates"] = f.read()
    
    return knowledge


@mcp.tool()
def start_content_discovery(niche: str, platform: str) -> str:
    """
    Start the content discovery process for a specific niche and platform.
    
    Args:
        niche: The topic/niche to research (e.g., "AI content creation tools")
        platform: The platform to scrape ("youtube", "tiktok", "instagram", "linkedin")
    
    Returns:
        Confirmation message with next steps
    """
    workflow_state["current_niche"] = niche
    workflow_state["selected_platform"] = platform.lower()
    
    return f"✅ Content discovery started for niche: '{niche}' on platform: '{platform}'\n\nNext: Use the appropriate scraping tool to discover content."


@mcp.tool()
def scrape_youtube_videos(search_query: str, max_results: int = 5) -> Dict[str, Any]:
    """
    Scrape YouTube videos for the given search query.
    
    Args:
        search_query: The search term/keyword
        max_results: Maximum number of videos to return (default: 5)
    
    Returns:
        Dictionary containing scraped video data
    """
    input_data = {
        "searchQueries": [search_query],
        "maxResults": max_results,
        "downloadSubtitles": True,
        "preferAutoGeneratedSubtitles": True,
        "saveSubsToKVS": True,
        "maxResultStreams": 0,
        "maxResultsShorts": 0
    }
    
    result = make_apify_request("streamers/youtube-scraper", input_data)
    
    if result["status"] == "success":
        workflow_state["discovered_content"] = result["data"][:5]  # Store top 5
        
        # Format response for user selection
        videos_summary = []
        for i, video in enumerate(workflow_state["discovered_content"], 1):
            videos_summary.append({
                "index": i,
                "title": video.get("title", "No title"),
                "author": video.get("channelName", "Unknown"),
                "views": video.get("viewCount", 0),
                "url": video.get("url", ""),
                "duration": video.get("duration", "Unknown")
            })
        
        return {
            "status": "success",
            "message": f"Found {len(videos_summary)} YouTube videos",
            "videos": videos_summary,
            "next_step": "Use select_content() to choose a video for analysis"
        }
    
    return result


@mcp.tool()
def scrape_tiktok_videos(hashtag: str, results_per_page: int = 15) -> Dict[str, Any]:
    """
    Scrape TikTok videos for the given hashtag.
    
    Args:
        hashtag: The hashtag to search (without #)
        results_per_page: Number of results to return (default: 15)
    
    Returns:
        Dictionary containing scraped TikTok data
    """
    input_data = {
        "hashtags": [hashtag],
        "resultsPerPage": results_per_page,
        "shouldDownloadCovers": False,
        "shouldDownloadSlideshowImages": False,
        "shouldDownloadSubtitles": True,
        "shouldDownloadVideos": False,
        "proxyCountryCode": "None"
    }
    
    result = make_apify_request("clockworks/tiktok-scraper", input_data)
    
    if result["status"] == "success":
        workflow_state["discovered_content"] = result["data"][:5]  # Store top 5
        
        # Format response for user selection
        videos_summary = []
        for i, video in enumerate(workflow_state["discovered_content"], 1):
            videos_summary.append({
                "index": i,
                "text": video.get("text", "No description"),
                "author": video.get("authorMeta", {}).get("name", "Unknown"),
                "plays": video.get("playCount", 0),
                "likes": video.get("diggCount", 0),
                "comments": video.get("commentCount", 0),
                "url": video.get("webVideoUrl", "")
            })
        
        return {
            "status": "success",
            "message": f"Found {len(videos_summary)} TikTok videos",
            "videos": videos_summary,
            "next_step": "Use select_content() to choose a video for analysis"
        }
    
    return result


@mcp.tool()
def scrape_instagram_posts(username: str, results_limit: int = 12) -> Dict[str, Any]:
    """
    Scrape Instagram posts from a profile.
    
    Args:
        username: Instagram username (without @)
        results_limit: Number of posts to scrape (default: 12)
    
    Returns:
        Dictionary containing scraped Instagram data
    """
    input_data = {
        "usernames": [username],
        "resultsLimit": results_limit
    }
    
    result = make_apify_request("apify/instagram-scraper", input_data)
    
    if result["status"] == "success":
        workflow_state["discovered_content"] = result["data"][:5]  # Store top 5
        
        # Format response for user selection
        posts_summary = []
        for i, post in enumerate(workflow_state["discovered_content"], 1):
            posts_summary.append({
                "index": i,
                "caption": post.get("caption", "No caption")[:100] + "...",
                "likes": post.get("likesCount", 0),
                "comments": post.get("commentsCount", 0),
                "url": post.get("url", ""),
                "timestamp": post.get("timestamp", "Unknown")
            })
        
        return {
            "status": "success",
            "message": f"Found {len(posts_summary)} Instagram posts",
            "posts": posts_summary,
            "next_step": "Use select_content() to choose a post for analysis"
        }
    
    return result


@mcp.tool()
def scrape_linkedin_posts(profile_url: str) -> Dict[str, Any]:
    """
    Scrape LinkedIn posts from a profile.
    
    Args:
        profile_url: Full LinkedIn profile URL
    
    Returns:
        Dictionary containing scraped LinkedIn data
    """
    input_data = {
        "profileUrl": profile_url
    }
    
    result = make_apify_request("apimaestro/linkedin-profile-posts", input_data)
    
    if result["status"] == "success":
        workflow_state["discovered_content"] = result["data"][:5]  # Store top 5
        
        # Format response for user selection
        posts_summary = []
        for i, post in enumerate(workflow_state["discovered_content"], 1):
            posts_summary.append({
                "index": i,
                "text": post.get("text", "No text")[:100] + "...",
                "likes": post.get("numLikes", 0),
                "comments": post.get("numComments", 0),
                "reposts": post.get("numReposts", 0),
                "url": post.get("url", "")
            })
        
        return {
            "status": "success",
            "message": f"Found {len(posts_summary)} LinkedIn posts",
            "posts": posts_summary,
            "next_step": "Use select_content() to choose a post for analysis"
        }
    
    return result


@mcp.tool()
def select_content(index: int) -> str:
    """
    Select a piece of content for detailed analysis.
    
    Args:
        index: The index of the content to select (1-based)
    
    Returns:
        Confirmation message with selected content details
    """
    if not workflow_state["discovered_content"]:
        return "❌ No content discovered yet. Please run a scraping tool first."
    
    if index < 1 or index > len(workflow_state["discovered_content"]):
        return f"❌ Invalid index. Please select between 1 and {len(workflow_state['discovered_content'])}"
    
    selected = workflow_state["discovered_content"][index - 1]
    workflow_state["selected_content"] = selected
    
    platform = workflow_state["selected_platform"]
    
    if platform == "youtube":
        title = selected.get("title", "Unknown title")
        author = selected.get("channelName", "Unknown author")
        return f"✅ Selected YouTube video: '{title}' by {author}\n\nNext: Use analyze_comments() to analyze engagement"
    
    elif platform == "tiktok":
        text = selected.get("text", "No description")[:50] + "..."
        author = selected.get("authorMeta", {}).get("name", "Unknown")
        return f"✅ Selected TikTok video: '{text}' by {author}\n\nNext: Use analyze_comments() to analyze engagement"
    
    elif platform == "instagram":
        caption = selected.get("caption", "No caption")[:50] + "..."
        return f"✅ Selected Instagram post: '{caption}'\n\nNext: Use analyze_comments() to analyze engagement"
    
    elif platform == "linkedin":
        text = selected.get("text", "No text")[:50] + "..."
        return f"✅ Selected LinkedIn post: '{text}'\n\nNext: Use analyze_comments() to analyze engagement"
    
    return "✅ Content selected successfully"


@mcp.tool()
def analyze_comments() -> Dict[str, Any]:
    """
    Analyze comments/engagement for the selected content.
    
    Returns:
        Dictionary containing comment analysis results
    """
    if not workflow_state["selected_content"]:
        return {"error": "No content selected. Please select content first."}
    
    platform = workflow_state["selected_platform"]
    selected = workflow_state["selected_content"]
    
    if platform == "youtube":
        video_url = selected.get("url", "")
        if not video_url:
            return {"error": "No video URL found"}
        
        input_data = {"videoURLs": [video_url]}
        result = make_apify_request("streamers/youtube-comments-scraper", input_data)
        
    elif platform == "tiktok":
        video_url = selected.get("webVideoUrl", "")
        if not video_url:
            return {"error": "No video URL found"}
        
        input_data = {
            "postURLs": [video_url],
            "commentsPerPost": 100
        }
        result = make_apify_request("clockworks/tiktok-comments-scraper", input_data)
        
    elif platform == "instagram":
        post_url = selected.get("url", "")
        if not post_url:
            return {"error": "No post URL found"}
        
        input_data = {"postUrls": [post_url]}
        result = make_apify_request("apify/instagram-comment-scraper", input_data)
        
    elif platform == "linkedin":
        post_url = selected.get("url", "")
        if not post_url:
            return {"error": "No post URL found"}
        
        input_data = {"postUrls": [post_url]}
        result = make_apify_request("apimaestro/linkedin-post-comments-replies-engagements-scraper-no-cookies", input_data)
        
    else:
        return {"error": f"Unsupported platform: {platform}"}
    
    if result["status"] == "success":
        comments = result["data"]
        
        # Analyze comments for insights
        analysis = analyze_comment_patterns(comments)
        workflow_state["analyzed_data"] = analysis
        
        return {
            "status": "success",
            "message": f"Analyzed {len(comments)} comments",
            "analysis": analysis,
            "next_step": "Use analyze_content_transcript() to analyze the main content"
        }
    
    return result


def analyze_comment_patterns(comments: List[Dict[str, Any]]) -> Dict[str, Any]:
    """Analyze comment patterns to extract insights."""
    if not comments:
        return {"error": "No comments to analyze"}
    
    # Extract comment texts
    comment_texts = []
    for comment in comments:
        text = comment.get("text", "") or comment.get("comment", "") or comment.get("content", "")
        if text:
            comment_texts.append(text.lower())
    
    # Simple pattern analysis
    pain_points = []
    questions = []
    positive_sentiment = 0
    negative_sentiment = 0
    
    # Keywords that indicate pain points
    pain_keywords = ["problem", "issue", "difficult", "hard", "struggle", "can't", "won't", "doesn't work"]
    question_words = ["how", "what", "why", "when", "where", "which"]
    positive_words = ["great", "awesome", "love", "amazing", "helpful", "thanks", "good"]
    negative_words = ["bad", "terrible", "hate", "useless", "waste", "wrong", "stupid"]
    
    for text in comment_texts:
        # Check for pain points
        if any(keyword in text for keyword in pain_keywords):
            pain_points.append(text[:100])
        
        # Check for questions
        if any(word in text for word in question_words) and "?" in text:
            questions.append(text[:100])
        
        # Simple sentiment analysis
        if any(word in text for word in positive_words):
            positive_sentiment += 1
        if any(word in text for word in negative_words):
            negative_sentiment += 1
    
    total_comments = len(comment_texts)
    neutral_sentiment = total_comments - positive_sentiment - negative_sentiment
    
    return {
        "total_comments": total_comments,
        "sentiment_distribution": {
            "positive": round((positive_sentiment / total_comments) * 100, 1) if total_comments > 0 else 0,
            "negative": round((negative_sentiment / total_comments) * 100, 1) if total_comments > 0 else 0,
            "neutral": round((neutral_sentiment / total_comments) * 100, 1) if total_comments > 0 else 0
        },
        "pain_points": pain_points[:3],  # Top 3
        "common_questions": questions[:3],  # Top 3
        "engagement_level": "high" if total_comments > 50 else "medium" if total_comments > 10 else "low"
    }


@mcp.tool()
def analyze_content_transcript() -> Dict[str, Any]:
    """
    Analyze the transcript/content of the selected item.
    
    Returns:
        Dictionary containing content analysis results
    """
    if not workflow_state["selected_content"]:
        return {"error": "No content selected. Please select content first."}
    
    selected = workflow_state["selected_content"]
    platform = workflow_state["selected_platform"]
    
    # Extract content based on platform
    content_text = ""
    
    if platform == "youtube":
        # Get subtitles/transcript
        content_text = selected.get("subtitles", "") or selected.get("description", "")
    elif platform == "tiktok":
        # Get video text/description
        content_text = selected.get("text", "")
    elif platform == "instagram":
        # Get caption
        content_text = selected.get("caption", "")
    elif platform == "linkedin":
        # Get post text
        content_text = selected.get("text", "")
    
    if not content_text:
        return {"error": "No content text found for analysis"}
    
    # Analyze content for key insights
    analysis = extract_content_insights(content_text)
    
    # Merge with existing analyzed data
    workflow_state["analyzed_data"].update(analysis)
    
    return {
        "status": "success",
        "message": "Content analysis completed",
        "analysis": analysis,
        "next_step": "Use select_hooks() to choose appropriate hooks from the knowledge base"
    }


def extract_content_insights(text: str) -> Dict[str, Any]:
    """Extract key insights from content text."""
    # Simple pattern matching for insights
    insights = {
        "quantitative_metrics": [],
        "frameworks": [],
        "pattern_interrupts": [],
        "transformation_stories": [],
        "core_message": ""
    }
    
    # Look for numbers and percentages
    import re
    
    # Find percentages
    percentages = re.findall(r'\b\d+%\b', text)
    
    # Find other numbers with context
    number_patterns = re.findall(r'\b\d+[xX]?\s*(?:times|more|less|increase|decrease|growth|roi|conversion)\b', text, re.IGNORECASE)
    
    # Find dollar amounts
    dollar_amounts = re.findall(r'\$[\d,]+(?:\.\d{2})?', text)
    
    insights["quantitative_metrics"] = list(set(percentages + number_patterns + dollar_amounts))[:5]
    
    # Look for framework keywords
    framework_keywords = ["framework", "system", "method", "process", "strategy", "approach", "technique"]
    framework_sentences = []
    
    sentences = text.split('.')
    for sentence in sentences:
        if any(keyword in sentence.lower() for keyword in framework_keywords):
            framework_sentences.append(sentence.strip()[:100])
    
    insights["frameworks"] = framework_sentences[:3]
    
    # Look for pattern interrupts (contrarian statements)
    interrupt_phrases = ["but here's the thing", "however", "the truth is", "what most people don't know", "contrary to", "opposite"]
    interrupts = []
    
    for sentence in sentences:
        if any(phrase in sentence.lower() for phrase in interrupt_phrases):
            interrupts.append(sentence.strip()[:100])
    
    insights["pattern_interrupts"] = interrupts[:3]
    
    # Extract core message (first substantial sentence)
    substantial_sentences = [s.strip() for s in sentences if len(s.strip()) > 20]
    if substantial_sentences:
        insights["core_message"] = substantial_sentences[0][:200]
    
    return insights


@mcp.tool()
def select_hooks(hook_indices: List[int]) -> Dict[str, Any]:
    """
    Select hooks from the knowledge base for content creation.
    
    Args:
        hook_indices: List of hook indices to select (1-based)
    
    Returns:
        Dictionary containing selected hooks and next steps
    """
    knowledge = load_knowledge_base()
    hooks_content = knowledge["hooks"]
    
    if not hooks_content or "placeholder" in hooks_content.lower():
        return {
            "error": "Knowledge base not loaded. Please update knowledge_base/hooks.md with actual hook templates."
        }
    
    # For now, return a placeholder response since we need the actual hooks
    workflow_state["selected_hooks"] = hook_indices
    
    return {
        "status": "success",
        "message": f"Selected {len(hook_indices)} hooks from knowledge base",
        "selected_hooks": hook_indices,
        "next_step": "Use generate_content_ideas() to create content concepts"
    }


@mcp.tool()
def generate_content_ideas() -> Dict[str, Any]:
    """
    Generate content ideas based on analyzed data and selected hooks.
    
    Returns:
        Dictionary containing generated content ideas
    """
    if not workflow_state["analyzed_data"]:
        return {"error": "No analyzed data available. Please analyze content first."}
    
    analyzed_data = workflow_state["analyzed_data"]
    
    # Generate content ideas based on analysis
    ideas = []
    
    # Use quantitative metrics if available
    metrics = analyzed_data.get("quantitative_metrics", [])
    if metrics:
        for metric in metrics[:2]:  # Use top 2 metrics
            idea = f"The #{1} mistake I see with {workflow_state['current_niche']}? {metric} of people focus on the wrong approach. After analyzing viral content, I discovered the real opportunity lies in [key insight]."
            ideas.append(idea)
    
    # Use pain points from comments
    pain_points = analyzed_data.get("pain_points", [])
    if pain_points:
        pain = pain_points[0][:50] + "..." if len(pain_points[0]) > 50 else pain_points[0]
        idea = f"I keep seeing the same problem: '{pain}'. Here's what most people get wrong about {workflow_state['current_niche']}..."
        ideas.append(idea)
    
    # Use core message
    core_message = analyzed_data.get("core_message", "")
    if core_message:
        idea = f"Unpopular opinion about {workflow_state['current_niche']}: {core_message[:100]}... This changes everything."
        ideas.append(idea)
    
    # Ensure we have at least one idea
    if not ideas:
        ideas.append(f"The truth about {workflow_state['current_niche']} that nobody talks about...")
    
    workflow_state["content_ideas"] = ideas[:3]  # Keep top 3
    
    return {
        "status": "success",
        "message": f"Generated {len(ideas)} content ideas",
        "ideas": ideas,
        "next_step": "Use generate_linkedin_posts() to create full LinkedIn posts"
    }


@mcp.tool()
def generate_linkedin_posts(selected_idea_index: int = 1) -> Dict[str, Any]:
    """
    Generate LinkedIn posts based on selected content idea.
    
    Args:
        selected_idea_index: Index of the content idea to use (1-based, default: 1)
    
    Returns:
        Dictionary containing generated LinkedIn posts
    """
    if not workflow_state["content_ideas"]:
        return {"error": "No content ideas available. Please generate content ideas first."}
    
    if selected_idea_index < 1 or selected_idea_index > len(workflow_state["content_ideas"]):
        selected_idea_index = 1  # Default to first idea
    
    selected_idea = workflow_state["content_ideas"][selected_idea_index - 1]
    analyzed_data = workflow_state["analyzed_data"]
    
    # Generate 3 different LinkedIn posts
    posts = []
    
    # Post 1: Problem-Solution format
    post1 = f"""{selected_idea}

After analyzing {workflow_state['selected_platform']} content in the {workflow_state['current_niche']} space, here's what I found:

❌ Most people focus on quantity over quality
✅ Top performers prioritize strategic insights

The difference? They understand that {analyzed_data.get('core_message', 'success comes from focused execution')[:100]}

What's your experience with this?"""

    # Post 2: Story-lesson format  
    post2 = f"""Last week, I dove deep into {workflow_state['current_niche']} content analysis.

The results were eye-opening:

{analyzed_data.get('quantitative_metrics', ['Key insight discovered'])[0] if analyzed_data.get('quantitative_metrics') else 'Key insight discovered'}

But here's what surprised me most: {selected_idea.split('?')[1] if '?' in selected_idea else 'The approach that works is often counterintuitive'}

This completely changed how I think about {workflow_state['current_niche']}.

Are you making this same mistake?"""

    # Post 3: Contrarian take
    post3 = f"""Unpopular opinion: {selected_idea}

Everyone talks about best practices in {workflow_state['current_niche']}, but nobody mentions:

• {analyzed_data.get('pain_points', ['Common challenge people face'])[0][:80] if analyzed_data.get('pain_points') else 'Common challenge people face'}
• The real opportunity lies in quality over quantity  
• {analyzed_data.get('core_message', 'Strategic thinking beats tactical execution')[:80]}

The data doesn't lie. Are you ready to try a different approach?

What's worked for you?"""

    posts = [post1, post2, post3]
    workflow_state["generated_posts"] = posts
    
    return {
        "status": "success",
        "message": "Generated 3 LinkedIn posts",
        "posts": posts,
        "selected_idea": selected_idea,
        "workflow_complete": True
    }


@mcp.tool()
def get_workflow_status() -> Dict[str, Any]:
    """
    Get the current status of the content generation workflow.
    
    Returns:
        Dictionary containing current workflow state and progress
    """
    return {
        "current_niche": workflow_state.get("current_niche"),
        "selected_platform": workflow_state.get("selected_platform"),
        "content_discovered": len(workflow_state.get("discovered_content", [])),
        "content_selected": workflow_state.get("selected_content") is not None,
        "data_analyzed": bool(workflow_state.get("analyzed_data")),
        "hooks_selected": bool(workflow_state.get("selected_hooks")),
        "ideas_generated": len(workflow_state.get("content_ideas", [])),
        "posts_generated": len(workflow_state.get("generated_posts", [])),
        "next_step": _get_next_step()
    }


def _get_next_step() -> str:
    """Determine the next step in the workflow."""
    if not workflow_state.get("current_niche"):
        return "Start with start_content_discovery()"
    elif not workflow_state.get("discovered_content"):
        return "Use a scraping tool (scrape_youtube_videos, scrape_tiktok_videos, etc.)"
    elif not workflow_state.get("selected_content"):
        return "Use select_content() to choose content for analysis"
    elif not workflow_state.get("analyzed_data"):
        return "Use analyze_comments() and analyze_content_transcript()"
    elif not workflow_state.get("selected_hooks"):
        return "Use select_hooks() to choose hooks from knowledge base"
    elif not workflow_state.get("content_ideas"):
        return "Use generate_content_ideas() to create content concepts"
    elif not workflow_state.get("generated_posts"):
        return "Use generate_linkedin_posts() to create final posts"
    else:
        return "Workflow complete! Posts generated successfully."


if __name__ == "__main__":
    mcp.run()
