#!/usr/bin/env python3
"""
LinkedIn Viral Content Generator MCP Server
Complete implementation with Railway deployment support
"""

import os
import json
import requests
import time
import re
from typing import Dict, Optional, Any, List
from pathlib import Path

from fastmcp import FastMCP
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

# Initialize FastMCP server
mcp = FastMCP("LinkedIn Viral Content Generator")

# Configuration - lazy loading to avoid startup issues
def get_config():
    return {
        "APIFY_TOKEN": os.getenv("APIFY_TOKEN"),
        "APIFY_BASE_URL": "https://api.apify.com/v2",
        "KNOWLEDGE_BASE_DIR": Path(__file__).parent / "knowledge_base",
    }

# Global storage for workflow state
workflow_state = {
    "current_niche": None,
    "selected_platform": None,
    "discovered_content": [],
    "selected_content": None,
    "analyzed_data": {},
    "selected_hooks": [],
    "content_ideas": [],
    "generated_posts": []
}


def make_apify_request(actor_id: str, input_data: Dict[str, Any]) -> Dict[str, Any]:
    """Make a request to an Apify actor and wait for completion."""
    config = get_config()
    APIFY_TOKEN = config["APIFY_TOKEN"]
    APIFY_BASE_URL = config["APIFY_BASE_URL"]
    
    if not APIFY_TOKEN:
        raise ValueError("APIFY_TOKEN environment variable is required")
    
    # Start the actor run
    run_url = f"{APIFY_BASE_URL}/acts/{actor_id}/runs"
    headers = {"Authorization": f"Bearer {APIFY_TOKEN}"}
    
    response = requests.post(run_url, json=input_data, headers=headers)
    response.raise_for_status()
    
    run_data = response.json()
    run_id = run_data["data"]["id"]
    
    # Poll for completion
    status_url = f"{APIFY_BASE_URL}/acts/{actor_id}/runs/{run_id}"
    max_wait = 300  # 5 minutes max
    wait_time = 0
    
    while wait_time < max_wait:
        status_response = requests.get(status_url, headers=headers)
        status_response.raise_for_status()
        status_data = status_response.json()
        
        if status_data["data"]["status"] == "SUCCEEDED":
            # Get the dataset items
            dataset_id = status_data["data"]["defaultDatasetId"]
            dataset_url = f"{APIFY_BASE_URL}/datasets/{dataset_id}/items"
            
            dataset_response = requests.get(dataset_url, headers=headers)
            dataset_response.raise_for_status()
            
            return {"status": "success", "data": dataset_response.json()}
        
        elif status_data["data"]["status"] in ["FAILED", "ABORTED", "TIMED-OUT"]:
            return {"status": "failed", "error": f"Actor run failed with status: {status_data['data']['status']}"}
        
        time.sleep(10)
        wait_time += 10
    
    return {"status": "failed", "error": "Actor run timed out"}


def load_knowledge_base() -> Dict[str, str]:
    """Load hook templates and content templates from knowledge base."""
    config = get_config()
    KNOWLEDGE_BASE_DIR = config["KNOWLEDGE_BASE_DIR"]
    HOOKS_FILE = KNOWLEDGE_BASE_DIR / "hooks.md"
    CONTENT_TEMPLATES_FILE = KNOWLEDGE_BASE_DIR / "content_templates.md"
    
    knowledge = {"hooks": "", "content_templates": ""}
    
    if HOOKS_FILE.exists():
        with open(HOOKS_FILE, "r", encoding="utf-8") as f:
            knowledge["hooks"] = f.read()
    
    if CONTENT_TEMPLATES_FILE.exists():
        with open(CONTENT_TEMPLATES_FILE, "r", encoding="utf-8") as f:
            knowledge["content_templates"] = f.read()
    
    return knowledge


@mcp.tool()
def start_content_discovery(niche: str, platform: str) -> str:
    """Start the content discovery process for a specific niche and platform."""
    workflow_state["current_niche"] = niche
    workflow_state["selected_platform"] = platform.lower()
    
    return f"‚úÖ Content discovery started for niche: '{niche}' on platform: '{platform}'\n\nNext: Use the appropriate scraping tool to discover content."


@mcp.tool()
def scrape_youtube_videos(search_query: str, max_results: int = 5) -> Dict[str, Any]:
    """Scrape YouTube videos for the given search query."""
    input_data = {
        "searchQueries": [search_query],
        "maxResults": max_results,
        "downloadSubtitles": True,
        "preferAutoGeneratedSubtitles": True,
        "saveSubsToKVS": True,
        "maxResultStreams": 0,
        "maxResultsShorts": 0
    }
    
    result = make_apify_request("streamers/youtube-scraper", input_data)
    
    if result["status"] == "success":
        workflow_state["discovered_content"] = result["data"][:5]
        
        videos_summary = []
        for i, video in enumerate(workflow_state["discovered_content"], 1):
            videos_summary.append({
                "index": i,
                "title": video.get("title", "No title"),
                "author": video.get("channelName", "Unknown"),
                "views": video.get("viewCount", 0),
                "url": video.get("url", ""),
                "duration": video.get("duration", "Unknown")
            })
        
        return {
            "status": "success",
            "message": f"Found {len(videos_summary)} YouTube videos",
            "videos": videos_summary,
            "next_step": "Use select_content() to choose a video for analysis"
        }
    
    return result


@mcp.tool()
def scrape_tiktok_videos(hashtag: str, results_per_page: int = 15) -> Dict[str, Any]:
    """Scrape TikTok videos for the given hashtag."""
    input_data = {
        "hashtags": [hashtag],
        "resultsPerPage": results_per_page,
        "shouldDownloadCovers": False,
        "shouldDownloadSlideshowImages": False,
        "shouldDownloadSubtitles": True,
        "shouldDownloadVideos": False,
        "proxyCountryCode": "None"
    }
    
    result = make_apify_request("clockworks/tiktok-scraper", input_data)
    
    if result["status"] == "success":
        workflow_state["discovered_content"] = result["data"][:5]
        
        videos_summary = []
        for i, video in enumerate(workflow_state["discovered_content"], 1):
            videos_summary.append({
                "index": i,
                "text": video.get("text", "No description"),
                "author": video.get("authorMeta", {}).get("name", "Unknown"),
                "plays": video.get("playCount", 0),
                "likes": video.get("diggCount", 0),
                "comments": video.get("commentCount", 0),
                "url": video.get("webVideoUrl", "")
            })
        
        return {
            "status": "success",
            "message": f"Found {len(videos_summary)} TikTok videos",
            "videos": videos_summary,
            "next_step": "Use select_content() to choose a video for analysis"
        }
    
    return result


@mcp.tool()
def scrape_instagram_posts(username: str, results_limit: int = 12) -> Dict[str, Any]:
    """Scrape Instagram posts from a profile."""
    input_data = {
        "usernames": [username],
        "resultsLimit": results_limit
    }
    
    result = make_apify_request("apify/instagram-scraper", input_data)
    
    if result["status"] == "success":
        workflow_state["discovered_content"] = result["data"][:5]
        
        posts_summary = []
        for i, post in enumerate(workflow_state["discovered_content"], 1):
            posts_summary.append({
                "index": i,
                "caption": post.get("caption", "No caption")[:100] + "...",
                "likes": post.get("likesCount", 0),
                "comments": post.get("commentsCount", 0),
                "url": post.get("url", ""),
                "timestamp": post.get("timestamp", "Unknown")
            })
        
        return {
            "status": "success",
            "message": f"Found {len(posts_summary)} Instagram posts",
            "posts": posts_summary,
            "next_step": "Use select_content() to choose a post for analysis"
        }
    
    return result


@mcp.tool()
def scrape_linkedin_posts(profile_url: str) -> Dict[str, Any]:
    """Scrape LinkedIn posts from a profile."""
    input_data = {
        "profileUrl": profile_url
    }
    
    result = make_apify_request("apimaestro/linkedin-profile-posts", input_data)
    
    if result["status"] == "success":
        workflow_state["discovered_content"] = result["data"][:5]
        
        posts_summary = []
        for i, post in enumerate(workflow_state["discovered_content"], 1):
            posts_summary.append({
                "index": i,
                "text": post.get("text", "No text")[:100] + "...",
                "likes": post.get("numLikes", 0),
                "comments": post.get("numComments", 0),
                "reposts": post.get("numReposts", 0),
                "url": post.get("url", "")
            })
        
        return {
            "status": "success",
            "message": f"Found {len(posts_summary)} LinkedIn posts",
            "posts": posts_summary,
            "next_step": "Use select_content() to choose a post for analysis"
        }
    
    return result


@mcp.tool()
def select_content(index: int) -> str:
    """Select a piece of content for detailed analysis."""
    if not workflow_state["discovered_content"]:
        return "‚ùå No content discovered yet. Please run a scraping tool first."
    
    if index < 1 or index > len(workflow_state["discovered_content"]):
        return f"‚ùå Invalid index. Please select between 1 and {len(workflow_state['discovered_content'])}"
    
    selected = workflow_state["discovered_content"][index - 1]
    workflow_state["selected_content"] = selected
    
    platform = workflow_state["selected_platform"]
    
    if platform == "youtube":
        title = selected.get("title", "Unknown title")
        author = selected.get("channelName", "Unknown author")
        return f"‚úÖ Selected YouTube video: '{title}' by {author}\n\nNext: Use analyze_comments() to analyze engagement"
    
    elif platform == "tiktok":
        text = selected.get("text", "No description")[:50] + "..."
        author = selected.get("authorMeta", {}).get("name", "Unknown")
        return f"‚úÖ Selected TikTok video: '{text}' by {author}\n\nNext: Use analyze_comments() to analyze engagement"
    
    elif platform == "instagram":
        caption = selected.get("caption", "No caption")[:50] + "..."
        return f"‚úÖ Selected Instagram post: '{caption}'\n\nNext: Use analyze_comments() to analyze engagement"
    
    elif platform == "linkedin":
        text = selected.get("text", "No text")[:50] + "..."
        return f"‚úÖ Selected LinkedIn post: '{text}'\n\nNext: Use analyze_comments() to analyze engagement"
    
    return "‚úÖ Content selected successfully"


@mcp.tool()
def analyze_comments() -> Dict[str, Any]:
    """Analyze comments/engagement for the selected content."""
    if not workflow_state["selected_content"]:
        return {"error": "No content selected. Please select content first."}
    
    platform = workflow_state["selected_platform"]
    selected = workflow_state["selected_content"]
    
    if platform == "youtube":
        video_url = selected.get("url", "")
        if not video_url:
            return {"error": "No video URL found"}
        
        input_data = {"videoURLs": [video_url]}
        result = make_apify_request("streamers/youtube-comments-scraper", input_data)
        
    elif platform == "tiktok":
        video_url = selected.get("webVideoUrl", "")
        if not video_url:
            return {"error": "No video URL found"}
        
        input_data = {
            "postURLs": [video_url],
            "commentsPerPost": 100
        }
        result = make_apify_request("clockworks/tiktok-comments-scraper", input_data)
        
    elif platform == "instagram":
        post_url = selected.get("url", "")
        if not post_url:
            return {"error": "No post URL found"}
        
        input_data = {"postUrls": [post_url]}
        result = make_apify_request("apify/instagram-comment-scraper", input_data)
        
    elif platform == "linkedin":
        post_url = selected.get("url", "")
        if not post_url:
            return {"error": "No post URL found"}
        
        input_data = {"postUrls": [post_url]}
        result = make_apify_request("apimaestro/linkedin-post-comments-replies-engagements-scraper-no-cookies", input_data)
        
    else:
        return {"error": f"Unsupported platform: {platform}"}
    
    if result["status"] == "success":
        comments = result["data"]
        analysis = analyze_comment_patterns(comments)
        workflow_state["analyzed_data"] = analysis
        
        return {
            "status": "success",
            "message": f"Analyzed {len(comments)} comments",
            "analysis": analysis,
            "next_step": "Use analyze_content_transcript() to analyze the main content"
        }
    
    return result


def analyze_comment_patterns(comments: List[Dict[str, Any]]) -> Dict[str, Any]:
    """Analyze comment patterns to extract insights."""
    if not comments:
        return {"error": "No comments to analyze"}
    
    comment_texts = []
    for comment in comments:
        text = comment.get("text", "") or comment.get("comment", "") or comment.get("content", "")
        if text:
            comment_texts.append(text.lower())
    
    pain_points = []
    questions = []
    positive_sentiment = 0
    negative_sentiment = 0
    
    pain_keywords = ["problem", "issue", "difficult", "hard", "struggle", "can't", "won't", "doesn't work"]
    question_words = ["how", "what", "why", "when", "where", "which"]
    positive_words = ["great", "awesome", "love", "amazing", "helpful", "thanks", "good"]
    negative_words = ["bad", "terrible", "hate", "useless", "waste", "wrong", "stupid"]
    
    for text in comment_texts:
        if any(keyword in text for keyword in pain_keywords):
            pain_points.append(text[:100])
        
        if any(word in text for word in question_words) and "?" in text:
            questions.append(text[:100])
        
        if any(word in text for word in positive_words):
            positive_sentiment += 1
        if any(word in text for word in negative_words):
            negative_sentiment += 1
    
    total_comments = len(comment_texts)
    neutral_sentiment = total_comments - positive_sentiment - negative_sentiment
    
    return {
        "total_comments": total_comments,
        "sentiment_distribution": {
            "positive": round((positive_sentiment / total_comments) * 100, 1) if total_comments > 0 else 0,
            "negative": round((negative_sentiment / total_comments) * 100, 1) if total_comments > 0 else 0,
            "neutral": round((neutral_sentiment / total_comments) * 100, 1) if total_comments > 0 else 0
        },
        "pain_points": pain_points[:3],
        "common_questions": questions[:3],
        "engagement_level": "high" if total_comments > 50 else "medium" if total_comments > 10 else "low"
    }


@mcp.tool()
def analyze_content_transcript() -> Dict[str, Any]:
    """Analyze the transcript/content of the selected item."""
    if not workflow_state["selected_content"]:
        return {"error": "No content selected. Please select content first."}
    
    selected = workflow_state["selected_content"]
    platform = workflow_state["selected_platform"]
    
    content_text = ""
    
    if platform == "youtube":
        content_text = selected.get("subtitles", "") or selected.get("description", "")
    elif platform == "tiktok":
        content_text = selected.get("text", "")
    elif platform == "instagram":
        content_text = selected.get("caption", "")
    elif platform == "linkedin":
        content_text = selected.get("text", "")
    
    if not content_text:
        return {"error": "No content text found for analysis"}
    
    analysis = extract_content_insights(content_text)
    workflow_state["analyzed_data"].update(analysis)
    
    return {
        "status": "success",
        "message": "Content analysis completed",
        "analysis": analysis,
        "next_step": "Use select_hooks() to choose appropriate hooks from the knowledge base"
    }


def extract_content_insights(text: str) -> Dict[str, Any]:
    """Extract key insights from content text."""
    insights = {
        "quantitative_metrics": [],
        "frameworks": [],
        "pattern_interrupts": [],
        "transformation_stories": [],
        "core_message": ""
    }
    
    # Find percentages
    percentages = re.findall(r'\b\d+%', text)
    
    # Find other numbers with context
    number_patterns = re.findall(r'\b\d+[xX]?\s*(?:times|more|less|increase|decrease|growth|roi|conversion|days|months|years)\b', text, re.IGNORECASE)
    
    # Find dollar amounts
    dollar_amounts = re.findall(r'\$[\d,]+(?:\.\d{2})?', text)
    
    insights["quantitative_metrics"] = list(set(percentages + number_patterns + dollar_amounts))[:5]
    
    # Look for framework keywords
    framework_keywords = ["framework", "system", "method", "process", "strategy", "approach", "technique"]
    framework_sentences = []
    
    sentences = text.split('.')
    for sentence in sentences:
        if any(keyword in sentence.lower() for keyword in framework_keywords):
            framework_sentences.append(sentence.strip()[:100])
    
    insights["frameworks"] = framework_sentences[:3]
    
    # Look for pattern interrupts (contrarian statements)
    interrupt_phrases = ["but here's the thing", "however", "the truth is", "what most people don't know", "contrary to", "opposite"]
    interrupts = []
    
    for sentence in sentences:
        if any(phrase in sentence.lower() for phrase in interrupt_phrases):
            interrupts.append(sentence.strip()[:100])
    
    insights["pattern_interrupts"] = interrupts[:3]
    
    # Extract core message (first substantial sentence)
    substantial_sentences = [s.strip() for s in sentences if len(s.strip()) > 20]
    if substantial_sentences:
        insights["core_message"] = substantial_sentences[0][:200]
    
    return insights


@mcp.tool()
def select_hooks(hook_indices: List[int]) -> Dict[str, Any]:
    """Select hooks from the knowledge base for content creation."""
    knowledge = load_knowledge_base()
    hooks_content = knowledge["hooks"]
    
    if not hooks_content or "placeholder" in hooks_content.lower():
        return {
            "error": "Knowledge base not loaded. Please update knowledge_base/hooks.md with actual hook templates."
        }
    
    workflow_state["selected_hooks"] = hook_indices
    
    return {
        "status": "success",
        "message": f"Selected {len(hook_indices)} hooks from knowledge base",
        "selected_hooks": hook_indices,
        "next_step": "Use generate_content_ideas() to create content concepts"
    }


@mcp.tool()
def generate_content_ideas() -> Dict[str, Any]:
    """Generate content ideas based on analyzed data and selected hooks."""
    if not workflow_state["analyzed_data"]:
        return {"error": "No analyzed data available. Please analyze content first."}
    
    analyzed_data = workflow_state["analyzed_data"]
    
    ideas = []
    
    # Use quantitative metrics if available
    metrics = analyzed_data.get("quantitative_metrics", [])
    if metrics:
        for metric in metrics[:2]:
            idea = f"The #1 mistake I see with {workflow_state['current_niche']}? {metric} of people focus on the wrong approach. After analyzing viral content, I discovered the real opportunity lies in [key insight]."
            ideas.append(idea)
    
    # Use pain points from comments
    pain_points = analyzed_data.get("pain_points", [])
    if pain_points:
        pain = pain_points[0][:50] + "..." if len(pain_points[0]) > 50 else pain_points[0]
        idea = f"I keep seeing the same problem: '{pain}'. Here's what most people get wrong about {workflow_state['current_niche']}..."
        ideas.append(idea)
    
    # Use core message
    core_message = analyzed_data.get("core_message", "")
    if core_message:
        idea = f"Unpopular opinion about {workflow_state['current_niche']}: {core_message[:100]}... This changes everything."
        ideas.append(idea)
    
    # Ensure we have at least one idea
    if not ideas:
        ideas.append(f"The truth about {workflow_state['current_niche']} that nobody talks about...")
    
    workflow_state["content_ideas"] = ideas[:3]
    
    return {
        "status": "success",
        "message": f"Generated {len(ideas)} content ideas",
        "ideas": ideas,
        "next_step": "Use generate_linkedin_posts() to create full LinkedIn posts"
    }


@mcp.tool()
def generate_linkedin_posts(selected_idea_index: int = 1) -> Dict[str, Any]:
    """Generate LinkedIn posts based on selected content idea."""
    if not workflow_state["content_ideas"]:
        return {"error": "No content ideas available. Please generate content ideas first."}
    
    if selected_idea_index < 1 or selected_idea_index > len(workflow_state["content_ideas"]):
        selected_idea_index = 1
    
    selected_idea = workflow_state["content_ideas"][selected_idea_index - 1]
    analyzed_data = workflow_state["analyzed_data"]
    
    posts = []
    
    # Post 1: Problem-Solution format
    post1 = f"""{selected_idea}

After analyzing {workflow_state['selected_platform']} content in the {workflow_state['current_niche']} space, here's what I found:

‚ùå Most people focus on quantity over quality
‚úÖ Top performers prioritize strategic insights

The difference? They understand that {analyzed_data.get('core_message', 'success comes from focused execution')[:100]}

What's your experience with this?"""

    # Post 2: Story-lesson format  
    post2 = f"""Last week, I dove deep into {workflow_state['current_niche']} content analysis.

The results were eye-opening:

{analyzed_data.get('quantitative_metrics', ['Key insight discovered'])[0] if analyzed_data.get('quantitative_metrics') else 'Key insight discovered'}

But here's what surprised me most: {selected_idea.split('?')[1] if '?' in selected_idea else 'The approach that works is often counterintuitive'}

This completely changed how I think about {workflow_state['current_niche']}.

Are you making this same mistake?"""

    # Post 3: Contrarian take
    post3 = f"""Unpopular opinion: {selected_idea}

Everyone talks about best practices in {workflow_state['current_niche']}, but nobody mentions:

‚Ä¢ {analyzed_data.get('pain_points', ['Common challenge people face'])[0][:80] if analyzed_data.get('pain_points') else 'Common challenge people face'}
‚Ä¢ The real opportunity lies in quality over quantity  
‚Ä¢ {analyzed_data.get('core_message', 'Strategic thinking beats tactical execution')[:80]}

The data doesn't lie. Are you ready to try a different approach?

What's worked for you?"""

    posts = [post1, post2, post3]
    workflow_state["generated_posts"] = posts
    
    return {
        "status": "success",
        "message": "Generated 3 LinkedIn posts",
        "posts": posts,
        "selected_idea": selected_idea,
        "workflow_complete": True
    }


@mcp.tool()
def get_workflow_status() -> Dict[str, Any]:
    """Get the current status of the content generation workflow."""
    return {
        "current_niche": workflow_state.get("current_niche"),
        "selected_platform": workflow_state.get("selected_platform"),
        "content_discovered": len(workflow_state.get("discovered_content", [])),
        "content_selected": workflow_state.get("selected_content") is not None,
        "data_analyzed": bool(workflow_state.get("analyzed_data")),
        "hooks_selected": bool(workflow_state.get("selected_hooks")),
        "ideas_generated": len(workflow_state.get("content_ideas", [])),
        "posts_generated": len(workflow_state.get("generated_posts", [])),
        "next_step": _get_next_step(),
        "apify_token_configured": bool(get_config()["APIFY_TOKEN"]),
        "knowledge_base_loaded": _check_knowledge_base()
    }


def _get_next_step() -> str:
    """Determine the next step in the workflow."""
    if not workflow_state.get("current_niche"):
        return "Start with start_content_discovery()"
    elif not workflow_state.get("discovered_content"):
        return "Use a scraping tool (scrape_youtube_videos, scrape_tiktok_videos, etc.)"
    elif not workflow_state.get("selected_content"):
        return "Use select_content() to choose content for analysis"
    elif not workflow_state.get("analyzed_data"):
        return "Use analyze_comments() and analyze_content_transcript()"
    elif not workflow_state.get("selected_hooks"):
        return "Use select_hooks() to choose hooks from knowledge base"
    elif not workflow_state.get("content_ideas"):
        return "Use generate_content_ideas() to create content concepts"
    elif not workflow_state.get("generated_posts"):
        return "Use generate_linkedin_posts() to create final posts"
    else:
        return "Workflow complete! Posts generated successfully."


def _check_knowledge_base() -> bool:
    """Check if knowledge base files exist."""
    config = get_config()
    KNOWLEDGE_BASE_DIR = config["KNOWLEDGE_BASE_DIR"]
    HOOKS_FILE = KNOWLEDGE_BASE_DIR / "hooks.md"
    CONTENT_TEMPLATES_FILE = KNOWLEDGE_BASE_DIR / "content_templates.md"
    return HOOKS_FILE.exists() and CONTENT_TEMPLATES_FILE.exists()


# Add Railway health check endpoint
@mcp.custom_route("/health", methods=["GET"])
def health_endpoint(request):
    """Health check endpoint for Railway."""
    from starlette.responses import JSONResponse
    
    config = get_config()
    return JSONResponse({
        "status": "healthy",
        "server": "LinkedIn Viral Content Generator MCP Server",
        "apify_token_configured": bool(config["APIFY_TOKEN"]),
        "knowledge_base_loaded": _check_knowledge_base(),
        "tools_count": 13,
        "mcp_endpoint": "/mcp"
    })


if __name__ == "__main__":
    port = int(os.getenv("PORT", 8000))
    
    print(f"üöÄ Starting LinkedIn Viral Content Generator MCP Server")
    print(f"üìç Port: {port}")
    print(f"üîë APIFY_TOKEN: {'‚úÖ Configured' if get_config()['APIFY_TOKEN'] else '‚ùå Missing'}")
    print(f"üìö Knowledge Base: {'‚úÖ Loaded' if _check_knowledge_base() else '‚ùå Missing'}")
    print(f"üõ†  Tools: 13 MCP tools available")
    print(f"üåê Health Check: /health")
    print(f"üîó MCP Endpoint: /mcp")
    
    # Start the server with proper Railway configuration
    mcp.run(host="0.0.0.0", port=port, transport="http")